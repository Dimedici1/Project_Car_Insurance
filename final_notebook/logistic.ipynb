{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Here we will consider two forms of logistic regression, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policy_tenure</th>\n",
       "      <th>age_of_car</th>\n",
       "      <th>age_of_policyholder</th>\n",
       "      <th>area_cluster</th>\n",
       "      <th>population_density</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>airbags</th>\n",
       "      <th>is_esc</th>\n",
       "      <th>is_adjustable_steering</th>\n",
       "      <th>...</th>\n",
       "      <th>engine_type_1.2 L K Series Engine</th>\n",
       "      <th>engine_type_1.2 L K12N Dualjet</th>\n",
       "      <th>engine_type_1.5 L U2 CRDi</th>\n",
       "      <th>engine_type_1.5 Turbocharged Revotorq</th>\n",
       "      <th>engine_type_1.5 Turbocharged Revotron</th>\n",
       "      <th>engine_type_F8D Petrol Engine</th>\n",
       "      <th>engine_type_G12B</th>\n",
       "      <th>engine_type_K Series Dual jet</th>\n",
       "      <th>engine_type_K10C</th>\n",
       "      <th>engine_type_i-DTEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515874</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>1</td>\n",
       "      <td>4990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672619</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2</td>\n",
       "      <td>27003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.841110</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>3</td>\n",
       "      <td>4076</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.900277</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.432692</td>\n",
       "      <td>4</td>\n",
       "      <td>21622</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596403</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>5</td>\n",
       "      <td>34738</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58587</th>\n",
       "      <td>0.355089</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.644231</td>\n",
       "      <td>8</td>\n",
       "      <td>8794</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58588</th>\n",
       "      <td>1.199642</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>14</td>\n",
       "      <td>7788</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58589</th>\n",
       "      <td>1.162273</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.451923</td>\n",
       "      <td>5</td>\n",
       "      <td>34738</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58590</th>\n",
       "      <td>1.236307</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>8</td>\n",
       "      <td>8794</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58591</th>\n",
       "      <td>0.124429</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.442308</td>\n",
       "      <td>8</td>\n",
       "      <td>8794</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58592 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       policy_tenure  age_of_car  age_of_policyholder  area_cluster  \\\n",
       "0           0.515874        0.05             0.644231             1   \n",
       "1           0.672619        0.02             0.375000             2   \n",
       "2           0.841110        0.02             0.384615             3   \n",
       "3           0.900277        0.11             0.432692             4   \n",
       "4           0.596403        0.11             0.634615             5   \n",
       "...              ...         ...                  ...           ...   \n",
       "58587       0.355089        0.13             0.644231             8   \n",
       "58588       1.199642        0.02             0.519231            14   \n",
       "58589       1.162273        0.05             0.451923             5   \n",
       "58590       1.236307        0.14             0.557692             8   \n",
       "58591       0.124429        0.02             0.442308             8   \n",
       "\n",
       "       population_density  make  model  airbags  is_esc  \\\n",
       "0                    4990     1      1        2       0   \n",
       "1                   27003     1      1        2       0   \n",
       "2                    4076     1      1        2       0   \n",
       "3                   21622     1      2        2       1   \n",
       "4                   34738     2      3        2       0   \n",
       "...                   ...   ...    ...      ...     ...   \n",
       "58587                8794     2      3        2       0   \n",
       "58588                7788     1      1        2       0   \n",
       "58589               34738     1      1        2       0   \n",
       "58590                8794     1      6        2       0   \n",
       "58591                8794     3      4        6       1   \n",
       "\n",
       "       is_adjustable_steering  ...  engine_type_1.2 L K Series Engine  \\\n",
       "0                           0  ...                                  0   \n",
       "1                           0  ...                                  0   \n",
       "2                           0  ...                                  0   \n",
       "3                           1  ...                                  0   \n",
       "4                           0  ...                                  0   \n",
       "...                       ...  ...                                ...   \n",
       "58587                       0  ...                                  0   \n",
       "58588                       0  ...                                  0   \n",
       "58589                       0  ...                                  0   \n",
       "58590                       1  ...                                  0   \n",
       "58591                       1  ...                                  0   \n",
       "\n",
       "       engine_type_1.2 L K12N Dualjet  engine_type_1.5 L U2 CRDi  \\\n",
       "0                                   0                          0   \n",
       "1                                   0                          0   \n",
       "2                                   0                          0   \n",
       "3                                   1                          0   \n",
       "4                                   0                          0   \n",
       "...                               ...                        ...   \n",
       "58587                               0                          0   \n",
       "58588                               0                          0   \n",
       "58589                               0                          0   \n",
       "58590                               0                          0   \n",
       "58591                               0                          1   \n",
       "\n",
       "       engine_type_1.5 Turbocharged Revotorq  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "...                                      ...   \n",
       "58587                                      0   \n",
       "58588                                      0   \n",
       "58589                                      0   \n",
       "58590                                      0   \n",
       "58591                                      0   \n",
       "\n",
       "       engine_type_1.5 Turbocharged Revotron  engine_type_F8D Petrol Engine  \\\n",
       "0                                          0                              1   \n",
       "1                                          0                              1   \n",
       "2                                          0                              1   \n",
       "3                                          0                              0   \n",
       "4                                          0                              0   \n",
       "...                                      ...                            ...   \n",
       "58587                                      0                              0   \n",
       "58588                                      0                              1   \n",
       "58589                                      0                              1   \n",
       "58590                                      0                              0   \n",
       "58591                                      0                              0   \n",
       "\n",
       "       engine_type_G12B  engine_type_K Series Dual jet  engine_type_K10C  \\\n",
       "0                     0                              0                 0   \n",
       "1                     0                              0                 0   \n",
       "2                     0                              0                 0   \n",
       "3                     0                              0                 0   \n",
       "4                     0                              0                 0   \n",
       "...                 ...                            ...               ...   \n",
       "58587                 0                              0                 0   \n",
       "58588                 0                              0                 0   \n",
       "58589                 0                              0                 0   \n",
       "58590                 0                              1                 0   \n",
       "58591                 0                              0                 0   \n",
       "\n",
       "       engine_type_i-DTEC  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "58587                   0  \n",
       "58588                   0  \n",
       "58589                   0  \n",
       "58590                   0  \n",
       "58591                   0  \n",
       "\n",
       "[58592 rows x 80 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can be deleted once the final notebook is created, just need it to import the data\n",
    "import pandas as pd\n",
    "dataset = pd.read_csv('../data/processed_data.csv')\n",
    "dataset.head()\n",
    "dataset.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['policy_tenure', 'age_of_car', 'age_of_policyholder', 'area_cluster',\n",
       "       'population_density', 'make', 'model', 'airbags', 'is_esc',\n",
       "       'is_adjustable_steering', 'is_tpms', 'is_parking_sensors',\n",
       "       'is_parking_camera', 'displacement', 'cylinder', 'gear_box',\n",
       "       'turning_radius', 'length', 'width', 'height', 'gross_weight',\n",
       "       'is_front_fog_lights', 'is_rear_window_wiper', 'is_rear_window_washer',\n",
       "       'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks',\n",
       "       'is_central_locking', 'is_power_steering',\n",
       "       'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror',\n",
       "       'is_ecw', 'is_speed_alert', 'ncap_rating', 'is_claim',\n",
       "       'torque_113Nm@4400rpm', 'torque_170Nm@4000rpm', 'torque_200Nm@1750rpm',\n",
       "       'torque_200Nm@3000rpm', 'torque_250Nm@2750rpm', 'torque_60Nm@3500rpm',\n",
       "       'torque_82.1Nm@3400rpm', 'torque_85Nm@3000rpm', 'torque_91Nm@4250rpm',\n",
       "       'power_113.45bhp@4000rpm', 'power_118.36bhp@5500rpm',\n",
       "       'power_40.36bhp@6000rpm', 'power_55.92bhp@5300rpm',\n",
       "       'power_61.68bhp@6000rpm', 'power_67.06bhp@5500rpm',\n",
       "       'power_88.50bhp@6000rpm', 'power_88.77bhp@4000rpm',\n",
       "       'power_97.89bhp@3600rpm', 'fuel_type_CNG', 'fuel_type_Diesel',\n",
       "       'fuel_type_Petrol', 'rear_brakes_Disc', 'rear_brakes_Drum',\n",
       "       'transmission_type_Automatic', 'transmission_type_Manual', 'segment_A',\n",
       "       'segment_B1', 'segment_B2', 'segment_C1', 'segment_C2',\n",
       "       'segment_Utility', 'steering_type_Electric', 'steering_type_Manual',\n",
       "       'steering_type_Power', 'engine_type_1.0 SCe',\n",
       "       'engine_type_1.2 L K Series Engine', 'engine_type_1.2 L K12N Dualjet',\n",
       "       'engine_type_1.5 L U2 CRDi', 'engine_type_1.5 Turbocharged Revotorq',\n",
       "       'engine_type_1.5 Turbocharged Revotron',\n",
       "       'engine_type_F8D Petrol Engine', 'engine_type_G12B',\n",
       "       'engine_type_K Series Dual jet', 'engine_type_K10C',\n",
       "       'engine_type_i-DTEC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[['policy_tenure', 'age_of_car', 'age_of_policyholder',\n",
    "       'area_cluster', 'population_density', 'make', 'model', 'airbags',\n",
    "       'is_esc', 'is_adjustable_steering', 'is_tpms', 'is_parking_sensors',\n",
    "       'is_parking_camera', 'displacement', 'cylinder', 'gear_box',\n",
    "       'turning_radius', 'length', 'width', 'height', 'gross_weight',\n",
    "       'is_front_fog_lights', 'is_rear_window_wiper', 'is_rear_window_washer',\n",
    "       'is_rear_window_defogger', 'is_brake_assist', 'is_power_door_locks',\n",
    "       'is_central_locking', 'is_power_steering',\n",
    "       'is_driver_seat_height_adjustable', 'is_day_night_rear_view_mirror',\n",
    "       'is_ecw', 'is_speed_alert', 'ncap_rating', 'is_claim',\n",
    "       'torque_113Nm@4400rpm', 'torque_170Nm@4000rpm', 'torque_200Nm@1750rpm',\n",
    "       'torque_200Nm@3000rpm', 'torque_250Nm@2750rpm', 'torque_60Nm@3500rpm',\n",
    "       'torque_82.1Nm@3400rpm', 'torque_85Nm@3000rpm', 'torque_91Nm@4250rpm',\n",
    "       'power_113.45bhp@4000rpm', 'power_118.36bhp@5500rpm',\n",
    "       'power_40.36bhp@6000rpm', 'power_55.92bhp@5300rpm',\n",
    "       'power_61.68bhp@6000rpm', 'power_67.06bhp@5500rpm',\n",
    "       'power_88.50bhp@6000rpm', 'power_88.77bhp@4000rpm',\n",
    "       'power_97.89bhp@3600rpm', 'fuel_type_CNG', 'fuel_type_Diesel',\n",
    "       'fuel_type_Petrol', 'rear_brakes_Disc', 'rear_brakes_Drum',\n",
    "       'transmission_type_Automatic', 'transmission_type_Manual', 'segment_A',\n",
    "       'segment_B1', 'segment_B2', 'segment_C1', 'segment_C2',\n",
    "       'segment_Utility', 'steering_type_Electric', 'steering_type_Manual',\n",
    "       'steering_type_Power', 'engine_type_1.0 SCe',\n",
    "       'engine_type_1.2 L K Series Engine', 'engine_type_1.2 L K12N Dualjet',\n",
    "       'engine_type_1.5 L U2 CRDi', 'engine_type_1.5 Turbocharged Revotorq',\n",
    "       'engine_type_1.5 Turbocharged Revotron',\n",
    "       'engine_type_F8D Petrol Engine', 'engine_type_G12B',\n",
    "       'engine_type_K Series Dual jet', 'engine_type_K10C',\n",
    "       'engine_type_i-DTEC']]\n",
    "dataset.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.14590347923681257\n",
      "Accuracy: 0.5454390306340131\n",
      "Precision: 0.08301404853128991\n",
      "Recall: 0.6018518518518519\n",
      "ROC-AUC score: 0.5717003489853075\n",
      "[[5937 5026]\n",
      " [ 301  455]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import KBinsDiscretizer, OneHotEncoder\n",
    "\n",
    "\n",
    "X = dataset.drop('is_claim', axis=1)\n",
    "y = dataset['is_claim']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the transformers\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('quartile', KBinsDiscretizer(n_bins=4, encode='onehot-dense', strategy='quantile'))\n",
    "])\n",
    "\n",
    "# create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, ['policy_tenure', 'population_density', 'is_adjustable_steering']),\n",
    "        ('cat', cat_transformer, ['area_cluster']),\n",
    "        ('age', age_transformer, ['age_of_car', 'age_of_policyholder'])\n",
    "    ])\n",
    "\n",
    "# build the logistic regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegressionCV(Cs=[0.001, 0.01, 0.1, 1], cv=10, penalty='l1', class_weight={0: 1, 1: 15} , solver='liblinear', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on the training set\n",
    "y_train_pred = model.predict(X_test)\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_train_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_train_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_train_pred))\n",
    "print(\"ROC-AUC score:\", roc_auc_score(y_test, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_train_pred))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# assuming y_test and y_train_pred are already defined\n",
    "\n",
    "results_all = {'Feature selection method': ['All'], \n",
    "        'F1 Score': [f1_score(y_test, y_train_pred, pos_label=1)], \n",
    "        'Accuracy': [accuracy_score(y_test, y_train_pred)], \n",
    "        'Precision': [precision_score(y_test, y_train_pred)], \n",
    "        'ROC-AUC score': [roc_auc_score(y_test, y_train_pred)],\n",
    "        'Recall': [recall_score(y_test, y_train_pred)]}\n",
    "\n",
    "df = pd.DataFrame(results_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation analysis: \n",
    "You can use correlation analysis to identify columns that are highly correlated with the target variable (i.e., whether a claim is made or not). You can calculate the correlation coefficient between each column and the target variable and select the columns with the highest correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variables most correlated with claims (correlation > 0.005) are as follows: \n",
      "is_claim                            1.000000\n",
      "policy_tenure                       0.078747\n",
      "age_of_car                          0.028172\n",
      "age_of_policyholder                 0.022435\n",
      "population_density                  0.017808\n",
      "is_adjustable_steering              0.013917\n",
      "cylinder                            0.013434\n",
      "segment_B2                          0.012714\n",
      "power_88.50bhp@6000rpm              0.012381\n",
      "torque_113Nm@4400rpm                0.012381\n",
      "is_front_fog_lights                 0.011825\n",
      "is_brake_assist                     0.010893\n",
      "is_driver_seat_height_adjustable    0.010686\n",
      "Name: is_claim, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = dataset.corr().abs()\n",
    "corr_claim = corr['is_claim'].sort_values(ascending=False)\n",
    "corr_claim = corr_claim[corr_claim > 0.01]\n",
    "corr_cols = list(corr_claim.index)\n",
    "print(f'The variables most correlated with claims (correlation > 0.005) are as follows: \\n{corr_claim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40191\n",
       "1    18401\n",
       "Name: is_esc, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.is_esc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "policy_tenure             0.078747\n",
       "age_of_car               -0.028172\n",
       "age_of_policyholder       0.022435\n",
       "area_cluster             -0.003497\n",
       "population_density       -0.017808\n",
       "make                     -0.000456\n",
       "model                     0.002642\n",
       "airbags                   0.002789\n",
       "is_esc                    0.002995\n",
       "is_adjustable_steering    0.013917\n",
       "Name: is_claim, dtype: float64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Select the independent variables with highest correlation to 'is_claim'\n",
    "corr_matrix = dataset.corr()\n",
    "highest_corr_vars = corr_matrix['is_claim'].nlargest(10).index\n",
    "corr_matrix['is_claim'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.1476982097186701\n",
      "Accuracy: 0.5450123730693746\n",
      "Precision: 0.084\n",
      "Recall: 0.6111111111111112\n",
      "ROC-AUC score: 0.575782683166611\n",
      "[[5925 5038]\n",
      " [ 294  462]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/63/x4r8bns93xq03nn8llf3hqj40000gn/T/ipykernel_38315/11009930.py:56: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "highest_corr_vars = corr_matrix['is_claim'].head(10).index\n",
    "X = dataset.drop('is_claim', axis=1)[highest_corr_vars]\n",
    "y = dataset['is_claim']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the transformers\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('quartile', KBinsDiscretizer(n_bins=4, encode='onehot-dense', strategy='quantile'))\n",
    "])\n",
    "\n",
    "# create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, ['policy_tenure', 'is_adjustable_steering', 'population_density']),\n",
    "        ('cat', cat_transformer, ['is_adjustable_steering', 'area_cluster', 'make', 'model', 'airbags', 'is_esc', 'is_adjustable_steering']),\n",
    "        ('age', age_transformer, ['age_of_policyholder', 'age_of_car'])\n",
    "    ])\n",
    "\n",
    "# build the logistic regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegressionCV(Cs=[0.001, 0.01, 0.1, 1], cv=10, penalty='l1', class_weight={0: 1, 1: 15} , solver='liblinear', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on the training set\n",
    "y_train_pred = model.predict(X_test)\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_train_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_train_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_train_pred))\n",
    "print(\"ROC-AUC score:\", roc_auc_score(y_test, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_train_pred))\n",
    "\n",
    "data2 = {'Feature selection method': ['Correlation'], \n",
    "         'F1 Score': [f1_score(y_test, y_train_pred, pos_label=1)], \n",
    "         'Accuracy': [accuracy_score(y_test, y_train_pred)], \n",
    "         'Precision': [precision_score(y_test, y_train_pred)], \n",
    "         'Recall': [recall_score(y_test, y_train_pred)],\n",
    "         'ROC-AUC score': [roc_auc_score(y_test, y_train_pred)]}\n",
    "\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "df = df.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.14426120273196735\n",
      "Accuracy: 0.5616520180902808\n",
      "Precision: 0.08252334667429007\n",
      "Recall: 0.5727513227513228\n",
      "ROC-AUC score: 0.5668189706888056\n",
      "[[6149 4814]\n",
      " [ 323  433]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Select the important features from the dataset\n",
    "important_features = highest_corr_vars\n",
    "\n",
    "# Split the dataset into training and testing sets, using only the important features\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[important_features], dataset['is_claim'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42, solver='liblinear')\n",
    "\n",
    "# Fit the model on the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "results = cross_validate(logreg, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"ROC-AUC score\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection algorithms: \n",
    "You can use feature selection algorithms like Recursive Feature Elimination (RFE), LASSO, or Ridge Regression to identify the most important columns. These algorithms use statistical techniques to identify the subset of columns that are most relevant for predicting the target variable.\n",
    "\n",
    "Whether to use Ridge or Lasso regression depends on the type of feature selection you are looking for. Ridge regression is best suited when you have many variables that are all relevant to the outcome, and you want to reduce the impact of multicollinearity. On the other hand, Lasso regression is more suited when you have many variables but only a few are important for the outcome, and you want to select only those variables. So for this, we will use Lasso regression, as we have many features that might not be of importance.\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) is a regularization technique that penalizes the absolute size of the coefficients in a linear model. The penalty term encourages smaller magnitude coefficients and can set some of them to zero, effectively performing feature selection by eliminating irrelevant or redundant features.\n",
    "\n",
    "In the case of logistic regression, Lasso can be used to select a subset of features that are most predictive of the outcome variable. The logistic regression model with Lasso regularization is also known as Lasso logistic regression. Lasso logistic regression can help prevent overfitting by reducing the number of features used in the model and improving the model's generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features:\n",
      "population_density   -2.558731e-07\n",
      "displacement          6.700019e-06\n",
      "height               -1.271012e-06\n",
      "gross_weight         -1.048795e-06\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(['is_claim'], axis=1), dataset['is_claim'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a Lasso regression model with alpha=0.1\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model on the training set\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Get the coefficients and corresponding column names\n",
    "coef = pd.Series(lasso.coef_, index=X_train.columns)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected features:\")\n",
    "print(coef[coef!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.11925925925925926\n",
      "Accuracy: 0.3912449867736155\n",
      "Precision: 0.06576797385620915\n",
      "Recall: 0.6388888888888888\n",
      "ROC-AUC score: 0.5065282718639463\n",
      "[[4102 6861]\n",
      " [ 273  483]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/63/x4r8bns93xq03nn8llf3hqj40000gn/T/ipykernel_38315/402978744.py:53: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df3, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[coef[coef!=0].index]\n",
    "y = dataset['is_claim']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create the transformers\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "age_transformer = Pipeline(steps=[\n",
    "    ('quartile', KBinsDiscretizer(n_bins=4, encode='onehot-dense', strategy='quantile'))\n",
    "])\n",
    "\n",
    "# create the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, ['population_density', 'displacement', 'height', 'gross_weight']),\n",
    "    ])\n",
    "\n",
    "# build the logistic regression model\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegressionCV(Cs=[0.001, 0.01, 0.1, 1], cv=10, penalty='l1', class_weight={0: 1, 1: 15} , solver='liblinear', max_iter=10000, random_state=42))\n",
    "])\n",
    "\n",
    "# train the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predict on the training set\n",
    "y_train_pred = model.predict(X_test)\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_train_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_train_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_train_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_train_pred))\n",
    "print(\"ROC-AUC score:\", roc_auc_score(y_test, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_train_pred))\n",
    "\n",
    "data3 = {'Feature selection method': ['Lasso'], \n",
    "         'F1 Score': [f1_score(y_test, y_train_pred, pos_label=1)], \n",
    "         'Accuracy': [accuracy_score(y_test, y_train_pred)], \n",
    "         'Precision': [precision_score(y_test, y_train_pred)], \n",
    "         'Recall': [recall_score(y_test, y_train_pred)],\n",
    "         'ROC-AUC score': [roc_auc_score(y_test, y_train_pred)]}\n",
    "\n",
    "df3 = pd.DataFrame(data3)\n",
    "\n",
    "df = df.append(df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.12105130149102854\n",
      "Accuracy: 0.4064339960747504\n",
      "Precision: 0.06691813355685945\n",
      "Recall: 0.6335978835978836\n",
      "ROC-AUC score: 0.512183416851391\n",
      "[[4284 6679]\n",
      " [ 277  479]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, make_scorer, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Select the important features from the dataset\n",
    "important_features = ['population_density', 'displacement', 'height', 'gross_weight']\n",
    "\n",
    "# Split the dataset into training and testing sets, using only the important features\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[important_features], dataset['is_claim'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42, solver='liblinear')\n",
    "\n",
    "# Fit the model on the training set\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "results = cross_validate(logreg, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"ROC-AUC score\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA): \n",
    "You can use PCA to reduce the dimensionality of the dataset and identify the most important columns. PCA transforms the original columns into a new set of uncorrelated variables (called principal components) that capture the maximum amount of variance in the dataset. You can then select the principal components with the highest variance as the most important columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split data into features and target variable\n",
    "X = dataset.drop('is_claim', axis=1)\n",
    "y = dataset['is_claim']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Find optimal number of components using PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "# Determine optimal number of components based on elbow point\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "optimal_num_components = np.argmax(cumulative_variance_ratio > 0.90) + 1\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.plot(pca.explained_variance_ratio_)\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.axvline(optimal_num_components, color='r')\n",
    "plt.show()\n",
    "\n",
    "# Transform training and testing data using PCA\n",
    "pca = PCA(n_components=optimal_num_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.12341289994921281\n",
      "Accuracy: 0.41087123474699205\n",
      "Precision: 0.06825842696629214\n",
      "Recall: 0.6428571428571429\n",
      "ROC-AUC score: 0.5188654044122438\n",
      "[[4329 6634]\n",
      " [ 270  486]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/63/x4r8bns93xq03nn8llf3hqj40000gn/T/ipykernel_38315/3494034905.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df4, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Import Logistic Regression from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression object\n",
    "logreg = LogisticRegression(class_weight={0: 1, 1: 15}, random_state=42, solver='liblinear')\n",
    "\n",
    "# Fit the model to the training data\n",
    "logreg.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict the labels of the test data\n",
    "y_pred = logreg.predict(X_test_pca)\n",
    "\n",
    "print('F1 Score:', f1_score(y_test, y_pred, pos_label=1))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"ROC-AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "data4 = {'Feature selection method': ['PCA'], \n",
    "         'F1 Score': [f1_score(y_test, y_pred, pos_label=1)], \n",
    "         'Accuracy': [accuracy_score(y_test, y_pred)], \n",
    "         'Precision': [precision_score(y_test, y_pred)], \n",
    "         'Recall': [recall_score(y_test, y_pred)],\n",
    "         'ROC-AUC score': [roc_auc_score(y_test, y_pred)]}\n",
    "\n",
    "df4 = pd.DataFrame(data4)\n",
    "\n",
    "df = df.append(df4, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature selection method</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ROC-AUC score:</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>0.145903</td>\n",
       "      <td>0.545439</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>0.571700</td>\n",
       "      <td>0.601852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Correlation</td>\n",
       "      <td>0.147698</td>\n",
       "      <td>0.545012</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.575783</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.119259</td>\n",
       "      <td>0.391245</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.506528</td>\n",
       "      <td>0.638889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCA</td>\n",
       "      <td>0.123413</td>\n",
       "      <td>0.410871</td>\n",
       "      <td>0.068258</td>\n",
       "      <td>0.518865</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Feature selection method  F1 Score  Accuracy  Precision  ROC-AUC score:  \\\n",
       "0                      All  0.145903  0.545439   0.083014        0.571700   \n",
       "1              Correlation  0.147698  0.545012   0.084000        0.575783   \n",
       "2                    Lasso  0.119259  0.391245   0.065768        0.506528   \n",
       "3                      PCA  0.123413  0.410871   0.068258        0.518865   \n",
       "\n",
       "     Recall  \n",
       "0  0.601852  \n",
       "1  0.611111  \n",
       "2  0.638889  \n",
       "3  0.642857  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
